/**
 * @license
 * Copyright 2017 Google Inc. All Rights Reserved.
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 * =============================================================================
 */

import * as data from '../data/index';
import {OperationMapper} from '../operations/index';

import {GraphExecutor} from './graph_executor';

export class Model {
  private executor: GraphExecutor;
  /**
   * @param modelUrl url for the model file generated by scripts/convert.py
   * script.
   * @param weightUrl url for the weight file generated by scripts/convert.py
   * script.
   */
  constructor(private modelUrl: string, private weightUrl: string) {}

  /**
   * Load the model and weight files, construct the in memory weight map and
   * compile the inference graph.
   */
  load(): Promise<boolean> {
    const graphPromise = data.loadRemoteProtoFile(this.modelUrl);
    const weightPromise = data.loadRemoteWeightFile(this.weightUrl);
    const weightMapPromise = data.buildWeightMap(graphPromise, weightPromise);
    const executorPromise = graphPromise.then(
        graph => this.executor =
            new GraphExecutor(OperationMapper.Instance.transformGraph(graph)));

    return Promise.all([weightMapPromise, executorPromise])
        .then(([weightMap, executor]) => {
          executor.weightMap = weightMap;
          return true;
        });
  }

  /**
   * Execute infrerence for the model for given input tensors.
   * @param inputs tensor map of the inputs for the model, keyed by the input
   * node names.
   */
  predict(inputs: data.TensorMap): data.TensorMap {
    return this.executor.execute(inputs);
  }

  /**
   * Release the memory used by the weight tensors.
   */
  dispose() {
    this.executor.dispose();
  }
}
